#ml #magistrale
# Cos'è il machine learning?
Il Machine Learning (ML) può essere definito come l'insieme di metodologie e tecniche che consentono lo sviluppo di modelli e algoritmi in grado di apprendere automaticamente dai dati e di migliorare progressivamente le proprie prestazioni nell'esecuzione di un compito, senza la necessità di istruzioni esplicite. Il processo di apprendimento viene formalizzato come un problema di ottimizzazione, in cui l'obiettivo è minimizzare l'errore rappresentato da una funzione di perdita (loss function), che quantifica la discrepanza tra le predizioni generate dal modello e i valori reali osservati. La quantità e la qualità dei dati disponibili assumono un ruolo cruciale, poiché influenzano direttamente accuratezza e robustezza del modello. In base alla natura dei dati e al tipo di feedback fornito durante l'addestramento, il machine learning si articola in tre paradigmi: Supervised learning, Unsupervised learning e Reinforcement learning.

---
# Supervised learning
Il supervised learning ha come obiettivo predire l'output $y$ a partire da un input $x$ mai visto prima, apprendendo le informazioni grazie a un insieme di dati etichettati (labelled) $D=\{(x_i,y_i)\}^n_{i=0}$ detto *dataset*, dove $x_i\in R^d$ appartiene allo spazio degli input (feature) $X$ mentre $y_i\in R^m$ appartiene allo spazio degli output (risultati) $Y$, $n$ indica la dimensione dell'insieme e la loro occorrenza comune è data dalla distribuzione di probabilità congiunta $P(X,Y)$. Gli input $x_i$,  saranno espressi tramite una notazione vettoriale di dimensione $p$, perciò $x=[x_1,x_2,...x_p]^T$. La rappresentazione più utilizzata per l'input è quella di vettori di numeri reali $x\in R^d$. Per rappresentazione quindi intendiamo il processo di mapping, da uno spazio ad un altro più facile da manipolare. Ad esempio un'immagine in bianco e nero altro non è che un vettore in due dimensioni (H per l'altezza e W per la larghezza), mentre per le immagini a colori, RGB, si hanno 3 canali che spaziano da 0 a 255, quindi si ha che l'input $x$, appartiene a $R^{H\times W\times3}$. Ogni coppia all'interno del training set $(x,y)$, è un'osservazione, e come detto l'obiettivo è determinare una funzione anche detta *modello* $f:R^d\rightarrow R^m$ dato un input $x^*$ mai visto prima tale che $\hat{y}=f(x^*)$≈$y$. Per affermare la generica abilità del modello, solitamente si dedica una porzione del dataset (15-25%) per il testing in maniera casuale.
In base al tipo di elementi di $Y$, si distinguono due casi di problemi. Se gli elementi di $Y$ sono classificati in categorie, dunque $Y$ è un insieme discreto di elementi non ordinabili, si ha un problema di **classificazione** dove l'algoritmo dovrà imparare a distinguere le diverse categorie di dati e successivamente assegnare una categoria a dati mai visti prima, mentre se gli elementi di $Y$ assumono valori numerici (numeri reali), dunque $Y$ è un insieme continuo ordinabile, si ha un problema di **regressione** dove l'algoritmo cerca di predire l'output studiando le relazioni di dipendenza tra input e output. Dunque solamente il tipo degli output $y$, discrimina la categoria del problema.

## Classificazione 
All'interno di un problema di classificazione, il numero di classi $C$ si assume noto e il loro ordine è arbitrario. In particolare se $C=2$ allora il problema si dice di classificazione binaria, con label pari a -1 e 1, oppure *negative*, *positive*. In generale in questi problemi cerchiamo un modello $f:R^d\rightarrow C$ con $y\in C$. Nella regressione abbiamo che l'etichette sono $y\in R^m$ con generalmente $m=1$. Anche in questo caso attraverso delle metriche, valutiamo le prestazioni. La più semplice è l'<font color=orange>errore quadratico medio</font> che valuta la differenza quadratica media tra i valori predetti e i valori target.
Una particolare attenzione nei problemi di classificazione va posta nei punti posti ai confini decisionali (decision boundary), in quanto nei pressi di tali punti lo spazio di input presenta un cambio repentino da una classe ad un'altra. ![[decision boundary.png | 200x300]]
Come facciamo però a capire se un modello si comporta bene o male? Attraverso delle metriche, la più semplice è l'<font color=orange>accuracy</font> che valuta la percentuale di istanze classificate correttamente. I metodi che utilizzano esplicitamente i dati di training per formulare la predizione sono detti *<font color=red>nonparametric</font>*, mentre nei metodi *<font color=red>parametric</font>* la predizione avviene tramite una funzione governata da un numero fisso di parametri. Dunque i dati di training terminata la fase di training, vengo accantonati. ^965cea

Gli algoritmi di supervised learning aggiustano i parametri iterativamente al fine di minimizzare l'errore, cioè la differenza tra il risultato calcolato $f(x)$ e il risultato reale $y(x)$, catturando effettivamente la relazione tra input e output. Tuttavia, addestrare il modello con una quantità eccessiva di dati non rappresenta la strategia ottimale, così come utilizzare un numero troppo ridotto di dati, poiché si corre il rischio di incorrere in *overfitting* e *underfitting*. L'<font color=orange>overfitting</font> accade quando il modello presenta performance alte su i dati con cui è stato addestrato e performance insufficienti in presenza di dati sconosciuti. L'<font color=green>underfitting</font> invece, si verifica quando il modello viene addestrato su pochi dati. Questo rende il modello incapace di individuare i pattern e fare predizioni su i dati. ^17b4c6

## Algoritmo Nearest Neighbour 
Nel supervised learning, esistono numerosi algoritmi per risolvere problemi di classificazione e regressione. Il Nearest Neighbour ($NN$) è un algoritmo nonparametric usato sia per la regressione che sia per la classificazione e rappresenta i dati del dataset come punti in uno spazio n-dimensionale, in cui ogni dimensione corrisponde a una delle $n$ caratteristiche (feature) che descrivono i campioni. Molti algoritmi si basano sull'idea che quanto più i punti $x_*$ appartenenti al test set, sono vicini ai punti $x_i$ del training set, allora la predizione $\hat{y}(x_*)$, sarà vicina al valore $y_i$. Un'idea valida che può essere facilmente implementata attraverso la distanza euclidea fra l'input di test e l'input di training $||x^{(a)}-x^{(b)}||_2=\displaystyle\sqrt{\sum_j^d(x_j^{(a)}-x_j^{(b)})^2}$ e utilizzando il punto $x^{(a)}$ che ha distanza minima da $x^{(b)}$ ed utilizzare il proprio output $\hat{y}(x^{(a)})$ come predizione.  Questa strategia corrisponde al 1-nearest neighbour, molto semplice ma suscettibile a dati rumorosi o etichettati male, ricordando che per rumore intendiamo fluttuazioni dati dalla casualità, dell'universo.

Come miglioria si individuano i $k$ punti più vicini e si assegna al output la classe più frequente tra questi vicini, mentre per la regressione si utilizza il valore medio degli output $y_i$. In questo approccio, la posizione assoluta dei punti è meno rilevante rispetto alla distanza relativa che li separa. Un'altra piccola variante che migliora l'algoritmo è quella di introdurre <font color=purple>voti pesati</font>, ovvero ogni voto di un vicino ha un peso pari all'inverso della distanza, dunque i punti più vicini hanno un peso maggiore.  Come esempio del $k-NN$ si può vedere il file `knn.ipynb`

Dato che il $k$ viene scelto dal utente prende il nome di *<font color=red>hyperparemeter</font>*, un parametro che bisogna impostare prima del learning dato che non si apprende dai dati. La sua scelta è molto importante in quanto se troppo piccolo, si può cadere nella problematica del overfitting, mentre se troppo grande il modello perderà capacità di predizione andando in underfitting. Purtroppo non esiste un valore di $k$ perfetto ma generalmente si usa $k<\sqrt n$.
Prendiamo ad esempio il caso in cui vogliamo classificare macchine tra classi quali: city car, sport car e SUV. Con in verde le city car, in rosso le sport car e in blu i SUV. Applicando il nearest neighbour si ha questo risultato che risulta però strano.
![[wrong scale.png|500x300]]
Questo perché un ultimo importante aspetto da valutare nel k-NN è la normalizzazione del input.  Un altro esempio, se il training set è formato da due variabili, $x=[x_1,x_2]^T$ dove $x_1$ appartiene ad un intervallo $[100,1100]$ e $x_2$ appartiene ad un intervallo $[0,1]$ allora la distanza euclidea sarà totalmente dominata da $x_1$. Al fine di limitare ciò si utilizzano varie strategie per normalizzare il vettore di input come ad esempio: la <font color=orange>min-max normalization</font>: $\displaystyle\hat{x}_j={x_j-min_h x_j^{(i)}\over max_i x_j^{(i)}-min_i x_j^{(i)}} \forall j=1,...d$ oppure utilizzare la media e la varianza per effettuare la <font color=orange>standardization</font>: $\displaystyle \hat{x}_j^{(i)}={x_j^{(i)}-\mu_j\over \sigma_j}$.

Per quanto riguarda il $k-NN$ per i problemi di regressione, l'approccio è quello di utilizzare una media dei valori che i vicini esprimono invece della maggioranza dei voti, andando ad utilizzare opzionalmente distanze pesate per calcolare tale media. Dunque dopo aver calcolato i $k$ esemplari di coppie $(x^{(i)},y^{(i)})$ più vicine all'istanza di test $x$, calcoliamo l'output della regressione come: $\displaystyle y^*={1\over k}\sum_{i=1}^k y^{(i)}$. ![[knn_reg.png|400x300]]
notiamo quindi come le distanze pesate graficano meglio la curva.

Dato che l'obiettivo del nostro modello è generalizzare dati mai visti prima, sia per lo più interessati all'accuracy sul test set $D_{test}$ in particolare: ![[testaccuracy.png|700x100]] Una possibile idea quindi potrebbe essere valutare diversi valori di $k$ e poi prendere quello con l'accuracy più alta. Ma è fondamentalmente sbagliato. Non si può dire con certezza che il modello lavori bene su dati mai visti, dato che non potrà mai vedere "tutti" i dati. Inoltre, e se quel valore di $k$ specifico, fosse ideale solo in quello specifico dataset? La morale è che <font color=red>non bisogna utilizzare i dati di test per confrontare diversi valori di iperparametri</font>.
Per valutare le configurazioni degli iperparametri si usa il <font color=orange>validation</font> set, che deve però essere sufficientemente grande affinché la valutazione delle performance siano affidabili. Le previsioni ottenute sui dati di validazione permettono di calcolare l'accuratezza e di scegliere l'insieme di parametri ottimali che produce la minor percentuale di errori. Tuttavia se il validation set diventa troppo grande, si avranno meno dati per il training set. In definitiva si capisce che è necessario suddividere il dataset in tre sottoinsiemi distinti, ciascuno destinato a uno scopo specifico: training, validation e test. Ma come suddividere il dataset in maniera opportuna senza incorrere in problemi di overfitting o underfitting? Attraverso la **cross-validation**.

### K-fold cross-validation e tuning hyperparemeters
Un primo approccio che vedremo è il <font color=blue>K-folds cross-validation</font>
Il dataset è suddiviso in training set e test set. In particolare il training set viene suddiviso in K-folds ![[k-folds.png|300x400]] e lo pseudocodice dell'algoritmo è il seguente:
```
for each hyperparemeter configuration
	for each split
		train model on K-1 folds
		validate on remaining data
choose configuration with best average accuracy
(optional) re-train the model on the entire training set		
```
Come criterio per scegliere la miglior configurazione, non è detto che si debba utilizzare l'accuracy media. Ma adesso nasce un altro problema. Come scegliere le configurazioni degli iperparametri da confrontare? Per ogni iperparametro, si ha un insieme o un range di valori scelti manualmente (ad esempio k=1,3,5,7,9). L'approccio più banale detto <font color=green>grid search</font> è di considerare ogni possibile combinazione delle configurazioni degli iperparametri. Ovviamente questo approccio non è praticabile quindi si opta per un approccio che è casuale, ovvero il <font color=green>random search</font>, che esplora $m$ configurazioni possibili scelte casualmente, abbassando di molto il tempo di ricerca, ma anche se è flessibile, il random search può perdere configurazioni ottimali. Come miglioria si introduce la <font color=blue>bayesian optimization</font>. Infatti l'ottimizzazione degli iperparametri è un esempio di black-box optimization, dove si ottimizza una funzione obiettivo che non si riesce a scrivere analiticamente, ma di cui le soluzioni candidate possono essere valutate. Sostanzialmente la bayesian optimization lavora come il random search, tenendo conto però di soluzioni "interessanti".

### Problemi della dimensionalità e di costo computazionale nel k-NN
Per dimensioni più alte la distanza euclidea diventa meno utile, questo perché la maggior parte dei punti si trova distante da altri, dunque si hanno distanze "uguali". Consideriamo ad esempio $N$ punti $x\in R^d$ uniformemente distribuiti in un iper-cubo unitario quindi con lati pari a 1 ($[0,1]^d$. Considerando un iper-cubo più piccolo con lato di lunghezza $l\le 1$, la frazione di punti che ci si aspetta di avere nel iper-cubo è $l^d$. Per ogni punto di test casuale, l'iper cubo più piccolo contiene almeno $k$ neighbours ha lato $\displaystyle l=({k\over N})^{1\over d}$. Andando a valutare i valori di $d$ e $l$ si ha che 

| d   | l    |
| --- | ---- |
| 2   | 0.10 |
| 3   | 0.22 |
| 10  | 0.63 |
| 100 | 0.96     |

e dato che ogni componente è nell'intervallo $[0,1]$ si nota come ben presto i vicini siano distanti tra loro. Per mitigare questo problema si posso utilizzare tecniche per ridurre la dimensionalità prima di applicare il $k-NN$. Infine se ragioniamo un attimo, si intuisce che tutti i calcoli computazionali nel $k-NN$ avvengono durante la fase di test per ogni singola predizione e che nel training il costo computazionale è pari a 0. Dunque si capisce che bisognerebbe memorizzare l'intero dataset nella RAM per utilizzare il $k-NN$ ma questa è pura follia.

--- 

## Metriche di valutazione
Nei problemi di classificazione binari ma anche in generale, l'accuracy espressa tramite una percentuale è la metrica più popolare per misurare le performance. Ricordiamo che l'accuracy è calcolata come: ${\text{N° di istanze classificate correttamente}\over \text{N° di istanze}}$ e che l'errore è pari a $1-accuracy$. Tuttavia essendo molto semplice rischia di non funzionare bene per classi altamente sbilanciate. Se ad esempio abbiamo un classificatore binario di malware, dove il dataset consiste in 100 programmi normali e 10 malware, l'accuracy è pari al 91%, dunque il modello non riconosce nessun malware al interno del dataset. Un modo semplice ed efficace di ispezionare la performance del modello attraverso più informazioni sul errore è la <font color=purple>confusion matrix</font> che separa per un classificatore binario le istanze del validation set quattro gruppi in base al output $y$ e l'output predetto dal classificatore $\hat{y}(x)$. Dunque in un classificatore binario dove le istanze possono essere classificate come positive o negative si ha:
- True Positive (TP): istanze positive classificate correttamente 
- True Negative (TN): istanze negative classificate correttamente 
- False Positive (FP): istanze negative classificate come positive 
- False Negative (FN): istanze positive classificate come negative 

In questo modo l'accuracy e errore sono calcolati come: $accuracy={TP+TN\over P+N}$ $error=1-{TP+TN\over P+N}={FP+FN\over P+N}$. All'interno, una cella della confusion matrix $(i,j)$ contiene una frazione del numero di volte in cui il modello predice $j$ quando in realtà il valore è $i$. ![[confusionmatrix.png|500x300]]
I valori fuori dalla diagonale della matrice rappresentano gli errori. Altre possibili metriche sono: la <font color=orange>recall</font>, calcolata come $recall={TP\over TP+FN}$ mentre come probabilità è $P(predicted\ pos | pos)$, che indica la frazione di istanze positive che sono correttamente identificate. Dunque un recall alto, vicino a 1 è ottimo, mentre un valore basso vicino a 0 indica problemi con la presenza di molti falsi negativi. La <font color=green>precision</font> calcolata come $precision={TP\over TP+FP}$ mentre come probabilità è $P( pos | predicted\ pos)$, che indica la frazione di predizioni positive che sono corrette, dove quindi un valore alto, vicino a 1 è ottimo, mentre un valore basso vicino a 0 indica la presenza di molti falsi positivi. Per i problemi di classificazione *sbilanciati*, ovvero dove la maggior parte delle istanze appartengono ad una classe, tipicamente quella negativa si utilizza la metrica <font color=orange>$F_1\ score$</font> pari alla media armonica della precision e recall: $\displaystyle F_1={2 \over{1\over precision}+{1\over recall}}=2\cdot{precision\cdot recall\over precision+recall}$. Il suo valore oscilla tra 0 e 1 e da più peso a valori piccoli. Si ha un $F_1\ score$ alto solo se si hanno contemporaneamente precision e recall alte. Per classificatori non binari invece possiamo estendere la definizione delle metriche? La risposta è ovviamente si, per ogni classe $c$ possiamo calcolare i valori di TP, TN, FP e FN e calcolare le rispettive metriche, per poi infine, calcolare una media delle metriche tra tutte le classi effettuando il cosidetto **macro averaging**. Nella seconda parte del file d'esempio del $k-NN$ andiamo a valutare tutto questo.

--- 

